{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster, wait, as_completed\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap the clients in a class to prevent\n",
    "# double init\n",
    "class MyClient:\n",
    "    mp = None\n",
    "    mt = None\n",
    "    modules = None \n",
    "    started = False\n",
    "\n",
    "    # Stats\n",
    "    p_workers = None \n",
    "    p_cores   = None \n",
    "    p_workers = None \n",
    "    p_cores   = None \n",
    "    \n",
    "    @staticmethod\n",
    "    def restart():\n",
    "        MyClient.mp.restart()\n",
    "        MyClient.mt.restart()\n",
    "    \n",
    "    @staticmethod\n",
    "    def init():\n",
    "        if MyClient.started is False:\n",
    "            # Start process cluster\n",
    "            print(\"Starting multiprocess cluster...\")\n",
    "            MyClient.mp = Client(scheduler_port=0, dashboard_address=None)\n",
    "            MyClient.p_workers = len(MyClient.mp.cluster.workers)\n",
    "            MyClient.p_cores = MyClient.mp.cluster.worker_kwargs['ncores']\n",
    "            print(\"Multiprocess cluster started w/ {} workers ({} cores each)\".format(MyClient.p_workers, MyClient.p_cores))\n",
    "            \n",
    "            # Start thread cluster\n",
    "            print(\"Starting multithread cluster...\")\n",
    "            MyClient.mt = Client(scheduler_port=0, dashboard_address=None, processes=False)\n",
    "            MyClient.t_workers = len(MyClient.mt.cluster.workers)\n",
    "            MyClient.t_cores = MyClient.mt.cluster.worker_kwargs['ncores']\n",
    "            print(\"Multithread cluster started w/ {} workers ({} cores each)\".format(MyClient.t_workers, MyClient.t_cores))\n",
    "            \n",
    "            # Toggle             \n",
    "            MyClient.started = True\n",
    "        else:\n",
    "            print(\"Multithread cluster already started\")\n",
    "            \n",
    "def init_parallel(module_names=None):\n",
    "    MyClient.init()    \n",
    "    if module_names is not None:\n",
    "        for name in module_names:\n",
    "            MyClient.mp.upload_file(name)\n",
    "            MyClient.mt.upload_file(name)\n",
    "    print(\n",
    "        \"\"\"\n",
    "        Parallel Plugin Loaded. You can now decorate functions with @profile(profile_array) \n",
    "        and @parallel(map=True, threads=True, background=False). MyClient and get_results(futures)\n",
    "        have also been loaded into your namespace.\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User decorators\n",
    "def profile(array_input):\n",
    "    def profile_decorator(f):\n",
    "        def profile_wrapper(*args, **kwargs):\n",
    "            # Stats\n",
    "            MyClient.restart() # clear cache\n",
    "            \n",
    "            print(\"---------Parallel vs Sequential Profile--------\")\n",
    "            print(\"Function: {}\".format(f.__name__))\n",
    "            print(\"Input length: {}\".format(len(array_input)))\n",
    "            print(\"Input type: {}\".format(type(array_input[0])))\n",
    "            print(\"Timing...\")\n",
    "            seq = MyClient.mp.submit(_time_sequential_map, f, array_input)\n",
    "            seq = seq.result()\n",
    "            par_processes = _time_parallel_map(f, array_input)\n",
    "            MyClient.restart() # clear cache\n",
    "            par_threads = _time_parallel_map(f, array_input, threads=False)\n",
    "            print(\"========================\")\n",
    "            print(\"Sequential time: {:.4f}s\".format(seq))\n",
    "            print(\"Multiprocessing time: {:.4f}s (~{:.4f}x speedup, {} workers, {} cores/worker)\".format(par_processes, seq/par_processes, MyClient.p_workers, MyClient.p_cores))\n",
    "            print(\"Multithreading time: {:.4f}s (~{:.4f}x speedup, {} workers, {} cores/worker)\".format(par_threads, seq/par_threads, MyClient.t_workers, MyClient.t_cores))\n",
    "        return profile_wrapper\n",
    "    return profile_decorator\n",
    "\n",
    "def parallel(map=False, threads=False, background=True):\n",
    "    def concurrent_decorator(func):\n",
    "        def wrapper_concurrent(*args, **kwargs):\n",
    "            client = MyClient.mt if threads else MyClient.mp\n",
    "            if map:\n",
    "                res = client.map(func, *args, **kwargs)\n",
    "            else:\n",
    "                res = client.submit(func, *args, **kwargs)\n",
    "            if background:\n",
    "                return res\n",
    "            else:\n",
    "                return [r for f, r in tqdm(as_completed(res, with_results=True), total=len(res))]\n",
    "        return wrapper_concurrent\n",
    "    return concurrent_decorator\n",
    "\n",
    "def get_results(futures):\n",
    "    return [f.result() for f in as_completed(futures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def _time_sequential_map(f, array):\n",
    "    ts = time.time()\n",
    "    for a in array:\n",
    "        result = f(a)\n",
    "    te = time.time()\n",
    "    time_ms = (te - ts)\n",
    "    return time_ms\n",
    "\n",
    "def _time_parallel_map(f, array, threads=False):\n",
    "    ts = time.time()\n",
    "    client = MyClient.mt if threads else MyClient.mp\n",
    "    futures = client.map(f, array)\n",
    "    wait(futures)\n",
    "    te = time.time()\n",
    "    time_ms = (te - ts)\n",
    "    return time_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
